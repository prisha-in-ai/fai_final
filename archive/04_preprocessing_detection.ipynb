{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cbdb6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/prisriva/Desktop/fai_final/data/raw/train/annotations.json',\n",
       " '/Users/prisriva/Desktop/fai_final/data/raw/val/annotations.json',\n",
       " '/Users/prisriva/Desktop/fai_final/data/raw/test/annotations.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Project root directory\n",
    "root_dir = \"/Users/prisriva/Desktop/fai_final\"\n",
    "\n",
    "# Dataset root\n",
    "data_dir = os.path.join(root_dir, \"data\", \"raw\")\n",
    "\n",
    "# Split directories\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir   = os.path.join(data_dir, \"val\")\n",
    "test_dir  = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Image folders\n",
    "train_img_dir = os.path.join(train_dir, \"images\")\n",
    "val_img_dir   = os.path.join(val_dir, \"images\")\n",
    "test_img_dir  = os.path.join(test_dir, \"images\")\n",
    "\n",
    "# Annotation files\n",
    "train_ann = os.path.join(train_dir, \"annotations.json\")\n",
    "val_ann   = os.path.join(val_dir, \"annotations.json\")\n",
    "test_ann  = os.path.join(test_dir, \"annotations.json\")\n",
    "\n",
    "train_ann, val_ann, test_ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7668b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " Train: 2816 images, 6211 annotations\n",
      " Val:   810 images, 1744 annotations\n",
      " Test:  374 images, 785 annotations\n"
     ]
    }
   ],
   "source": [
    "def load_coco_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_coco_json(train_ann)\n",
    "val_data   = load_coco_json(val_ann)\n",
    "test_data  = load_coco_json(test_ann)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\" Train:\", len(train_data[\"images\"]), \"images,\", len(train_data[\"annotations\"]), \"annotations\")\n",
    "print(\" Val:  \", len(val_data[\"images\"]),   \"images,\", len(val_data[\"annotations\"]),   \"annotations\")\n",
    "print(\" Test: \", len(test_data[\"images\"]),  \"images,\", len(test_data[\"annotations\"]),  \"annotations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b61f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardd_detection_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    For detection models:\n",
    "    batch = [(image, target), (image, target), ...]\n",
    "\n",
    "    Return:\n",
    "        images: list[Tensor]\n",
    "        targets: list[dict]\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59139c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cardd_split(root_dir: str, split: str, transforms=None):\n",
    "    \"\"\"\n",
    "    Loads one of the dataset splits:\n",
    "        split in {\"train\", \"val\", \"test\"}\n",
    "\n",
    "    Assumes directory structure:\n",
    "        {root_dir}/{split}/images/\n",
    "        {root_dir}/{split}/annotations.json\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(root_dir, split, \"images\")\n",
    "    ann_path = os.path.join(root_dir, split, \"annotations.json\")\n",
    "\n",
    "    if not os.path.exists(images_dir):\n",
    "        raise FileNotFoundError(f\"Images folder not found: {images_dir}\")\n",
    "\n",
    "    if not os.path.exists(ann_path):\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {ann_path}\")\n",
    "\n",
    "    return CarDDDetectionDataset(images_dir, ann_path, transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7105dd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TRAIN REPORT ---\n",
      "Images listed in JSON : 2816\n",
      "Missing image files   : 0\n",
      "\n",
      "--- VAL REPORT ---\n",
      "Images listed in JSON : 810\n",
      "Missing image files   : 0\n",
      "\n",
      "--- TEST REPORT ---\n",
      "Images listed in JSON : 374\n",
      "Missing image files   : 0\n"
     ]
    }
   ],
   "source": [
    "def verify_image_files(coco_data, img_dir, split_name):\n",
    "    json_images = coco_data[\"images\"]\n",
    "\n",
    "    missing = []\n",
    "\n",
    "    for img_entry in json_images:\n",
    "        fname = img_entry[\"file_name\"]\n",
    "        path = os.path.join(img_dir, fname)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            missing.append(fname)\n",
    "\n",
    "    print(f\"\\n--- {split_name.upper()} REPORT ---\")\n",
    "    print(f\"Images listed in JSON : {len(json_images)}\")\n",
    "    print(f\"Missing image files   : {len(missing)}\")\n",
    "\n",
    "    if missing:\n",
    "        print(\"\\nExamples of missing files:\")\n",
    "        for m in missing[:10]:\n",
    "            print(\"   -\", m)\n",
    "\n",
    "    return missing\n",
    "\n",
    "missing_train = verify_image_files(train_data, train_img_dir, \"train\")\n",
    "missing_val   = verify_image_files(val_data,   val_img_dir,   \"val\")\n",
    "missing_test  = verify_image_files(test_data,  test_img_dir,  \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a21ae992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TRAIN ANNOTATION STATS ---\n",
      "Total annotations: 6211\n",
      "Class distribution:\n",
      "  Class 1: 1806\n",
      "  Class 2: 2560\n",
      "  Class 3: 651\n",
      "  Class 4: 475\n",
      "  Class 5: 494\n",
      "  Class 6: 225\n",
      "Bad boxes: 0\n",
      "\n",
      "--- VAL ANNOTATION STATS ---\n",
      "Total annotations: 1744\n",
      "Class distribution:\n",
      "  Class 1: 501\n",
      "  Class 2: 728\n",
      "  Class 3: 177\n",
      "  Class 4: 135\n",
      "  Class 5: 141\n",
      "  Class 6: 62\n",
      "Bad boxes: 0\n",
      "\n",
      "--- TEST ANNOTATION STATS ---\n",
      "Total annotations: 785\n",
      "Class distribution:\n",
      "  Class 1: 236\n",
      "  Class 2: 307\n",
      "  Class 3: 70\n",
      "  Class 4: 71\n",
      "  Class 5: 69\n",
      "  Class 6: 32\n",
      "Bad boxes: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def analyze_coco_annotations(coco_data, split_name):\n",
    "    anns = coco_data[\"annotations\"]\n",
    "\n",
    "    cls_counts = defaultdict(int)\n",
    "\n",
    "    for ann in anns:\n",
    "        cls_counts[ann[\"category_id\"]] += 1\n",
    "\n",
    "    print(f\"\\n--- {split_name.upper()} ANNOTATION STATS ---\")\n",
    "    print(\"Total annotations:\", len(anns))\n",
    "    print(\"Class distribution:\")\n",
    "\n",
    "    for cls_id, count in sorted(cls_counts.items()):\n",
    "        print(f\"  Class {cls_id}: {count}\")\n",
    "\n",
    "    # bbox sanity checks\n",
    "    bad_boxes = []\n",
    "    for ann in anns:\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        if w <= 0 or h <= 0:\n",
    "            bad_boxes.append(ann[\"id\"])\n",
    "\n",
    "    print(\"Bad boxes:\", len(bad_boxes))\n",
    "    return cls_counts, bad_boxes\n",
    "\n",
    "train_stats = analyze_coco_annotations(train_data, \"train\")\n",
    "val_stats   = analyze_coco_annotations(val_data,   \"val\")\n",
    "test_stats  = analyze_coco_annotations(test_data,  \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db186b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example (train image -> classes):\n",
      "1 : [2, 6]\n",
      "2 : [6]\n",
      "3 : [6]\n",
      "4 : [6]\n",
      "5 : [6]\n"
     ]
    }
   ],
   "source": [
    "def extract_image_to_classes(coco_data):\n",
    "    mapping = defaultdict(set)\n",
    "\n",
    "    for ann in coco_data[\"annotations\"]:\n",
    "        img_id = ann[\"image_id\"]\n",
    "        cls_id = ann[\"category_id\"]\n",
    "        mapping[img_id].add(cls_id)\n",
    "\n",
    "    # convert sets to lists to match your classification preprocessing\n",
    "    final_map = {k: sorted(list(v)) for k, v in mapping.items()}\n",
    "    return final_map\n",
    "\n",
    "\n",
    "train_img_classes = extract_image_to_classes(train_data)\n",
    "val_img_classes   = extract_image_to_classes(val_data)\n",
    "test_img_classes  = extract_image_to_classes(test_data)\n",
    "\n",
    "print(\"\\nExample (train image -> classes):\")\n",
    "for k in list(train_img_classes.keys())[:5]:\n",
    "    print(k, \":\", train_img_classes[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa1d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example image_id: 1\n",
      "File name: 000001.jpg\n",
      "Classes: [2, 6]\n",
      "\n",
      "Bounding boxes:\n",
      "  bbox: [167.04, 40.21, 202.79, 131.34] class: 2\n",
      "  bbox: [160.66, 112.45, 684.19, 551.02] class: 6\n"
     ]
    }
   ],
   "source": [
    "example_id = list(train_img_classes.keys())[0]\n",
    "\n",
    "print(\"\\nExample image_id:\", example_id)\n",
    "print(\"File name:\", next(img[\"file_name\"] for img in train_data[\"images\"] if img[\"id\"] == example_id))\n",
    "print(\"Classes:\", train_img_classes[example_id])\n",
    "\n",
    "# Show boxes\n",
    "print(\"\\nBounding boxes:\")\n",
    "for ann in train_data[\"annotations\"]:\n",
    "    if ann[\"image_id\"] == example_id:\n",
    "        print(\"  bbox:\", ann[\"bbox\"], \"class:\", ann[\"category_id\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cardd)",
   "language": "python",
   "name": "cardd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
