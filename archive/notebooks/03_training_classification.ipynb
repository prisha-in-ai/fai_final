{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14033777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from cardd_dataset import CarDDMultiLabelDataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aea847d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 2816 images loaded\n",
      "val: 810 images loaded\n",
      "category mapping (category_id -> index): {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5}\n",
      "classes: ['dent', 'scratch', 'crack', 'glass shatter', 'lamp broken', 'tire flat']\n"
     ]
    }
   ],
   "source": [
    "data_root = \"../data/raw\"\n",
    "\n",
    "train_json_path = os.path.join(data_root, \"train\", \"annotations.json\")\n",
    "train_img_dir = os.path.join(data_root, \"train\", \"images\")\n",
    "\n",
    "val_json_path = os.path.join(data_root, \"val\", \"annotations.json\")\n",
    "val_img_dir = os.path.join(data_root, \"val\", \"images\")\n",
    "\n",
    "num_classes = 6  # dent, scratch, crack, glass shatter, lamp broken, tire flat\n",
    "\n",
    "\n",
    "def load_coco_multilabel(json_path, img_dir, num_classes):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # category_id -> index [0..num_classes-1]\n",
    "    cat_ids = sorted([c[\"id\"] for c in coco[\"categories\"]])\n",
    "    cat_id_to_index = {cid: i for i, cid in enumerate(cat_ids)}\n",
    "\n",
    "    # image_id -> file_name\n",
    "    id_to_file = {im[\"id\"]: im[\"file_name\"] for im in coco[\"images\"]}\n",
    "\n",
    "    # image_id -> set of class indices\n",
    "    image_to_classes = {img_id: set() for img_id in id_to_file.keys()}\n",
    "    for ann in coco[\"annotations\"]:\n",
    "        img_id = ann[\"image_id\"]\n",
    "        cid = ann[\"category_id\"]\n",
    "        if cid in cat_id_to_index:\n",
    "            image_to_classes[img_id].add(cat_id_to_index[cid])\n",
    "\n",
    "    samples = []\n",
    "    for img_id, file_name in id_to_file.items():\n",
    "        label = np.zeros(num_classes, dtype=np.float32)\n",
    "        for cls_idx in image_to_classes[img_id]:\n",
    "            label[cls_idx] = 1.0\n",
    "\n",
    "        samples.append(\n",
    "            {\n",
    "                \"image_path\": os.path.join(img_dir, file_name),\n",
    "                \"label\": label,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(f\"{os.path.basename(os.path.dirname(json_path))}: {len(samples)} images loaded\")\n",
    "    return samples, cat_id_to_index, coco[\"categories\"]\n",
    "\n",
    "\n",
    "train_samples, cat_id_to_index, categories = load_coco_multilabel(\n",
    "    train_json_path, train_img_dir, num_classes\n",
    ")\n",
    "\n",
    "val_samples, _, _ = load_coco_multilabel(\n",
    "    val_json_path, val_img_dir, num_classes\n",
    ")\n",
    "\n",
    "print(\"category mapping (category_id -> index):\", cat_id_to_index)\n",
    "print(\"classes:\", [c[\"name\"] for c in categories])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9024dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDDMultiLabelDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img_path = sample[\"image_path\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label_tensor = torch.from_numpy(label)  # shape: (num_classes,)\n",
    "        return image, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa33108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 88 val batches: 26\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.02,\n",
    "    ),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = CarDDMultiLabelDataset(train_samples, transform=train_transform)\n",
    "val_dataset = CarDDMultiLabelDataset(val_samples, transform=val_transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(\"train batches:\", len(train_loader), \"val batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d15ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(\"using device:\", device)\n",
    "\n",
    "# load imagenet-pretrained resnet50\n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "in_features = resnet.fc.in_features\n",
    "\n",
    "# small dense head: 2048 -> 256 -> 6\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes),\n",
    ")\n",
    "\n",
    "model = resnet.to(device)\n",
    "\n",
    "print(model.fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13096448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['dent', 'scratch', 'crack', 'glass shatter', 'lamp broken', 'tire flat']\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=5,          # restart every 5 epochs\n",
    "    T_mult=2,       # restarts get farther apart\n",
    "    eta_min=1e-6    # minimum LR\n",
    ")\n",
    "\n",
    "class_names = [c[\"name\"] for c in categories]\n",
    "print(\"classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49b6c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_accuracy(logits, targets, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute multi-label accuracy.\n",
    "    Accuracy = % of labels that match the ground truth (per sample).\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > threshold).float()\n",
    "\n",
    "    correct = (preds == targets).float().mean()  # mean across classes per sample\n",
    "    return correct.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98dfc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_to_preds(logits, threshold=0.5):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return (probs >= threshold).float()\n",
    "\n",
    "\n",
    "def update_metrics(logits, targets, metrics):\n",
    "    preds = sigmoid_to_preds(logits)\n",
    "\n",
    "    tp = (preds * targets).sum(dim=0)\n",
    "    fp = (preds * (1 - targets)).sum(dim=0)\n",
    "    fn = ((1 - preds) * targets).sum(dim=0)\n",
    "\n",
    "    metrics[\"tp\"] += tp.cpu()\n",
    "    metrics[\"fp\"] += fp.cpu()\n",
    "    metrics[\"fn\"] += fn.cpu()\n",
    "\n",
    "\n",
    "def compute_f1(metrics):\n",
    "    tp = metrics[\"tp\"]\n",
    "    fp = metrics[\"fp\"]\n",
    "    fn = metrics[\"fn\"]\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    micro_tp = tp.sum()\n",
    "    micro_fp = fp.sum()\n",
    "    micro_fn = fn.sum()\n",
    "\n",
    "    micro_precision = micro_tp / (micro_tp + micro_fp + 1e-8)\n",
    "    micro_recall = micro_tp / (micro_tp + micro_fn + 1e-8)\n",
    "    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision.numpy(),\n",
    "        \"recall\": recall.numpy(),\n",
    "        \"f1\": f1.numpy(),\n",
    "        \"micro_f1\": micro_f1.item(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0378a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "  Train Loss: 0.0813 | Train Acc: 0.9676\n",
      "  Val Loss:   0.2541 | Val Acc:   0.9097\n",
      "  Val Micro F1: 0.8218\n",
      "    dent            F1: 0.8317\n",
      "    scratch         F1: 0.8359\n",
      "    crack           F1: 0.6496\n",
      "    glass shatter   F1: 0.9286\n",
      "    lamp broken     F1: 0.7518\n",
      "    tire flat       F1: 0.9174\n",
      "  Saved new best model → resnet50_multilabel_cardd_best.pt\n",
      "\n",
      "Epoch 2/20\n",
      "  Train Loss: 0.0599 | Train Acc: 0.9775\n",
      "  Val Loss:   0.2889 | Val Acc:   0.9121\n",
      "  Val Micro F1: 0.8325\n",
      "    dent            F1: 0.8238\n",
      "    scratch         F1: 0.8421\n",
      "    crack           F1: 0.6996\n",
      "    glass shatter   F1: 0.9663\n",
      "    lamp broken     F1: 0.7806\n",
      "    tire flat       F1: 0.9256\n",
      "  Saved new best model → resnet50_multilabel_cardd_best.pt\n",
      "\n",
      "Epoch 3/20\n",
      "  Train Loss: 0.0350 | Train Acc: 0.9871\n",
      "  Val Loss:   0.3584 | Val Acc:   0.9148\n",
      "  Val Micro F1: 0.8390\n",
      "    dent            F1: 0.8443\n",
      "    scratch         F1: 0.8495\n",
      "    crack           F1: 0.6989\n",
      "    glass shatter   F1: 0.9556\n",
      "    lamp broken     F1: 0.7770\n",
      "    tire flat       F1: 0.9381\n",
      "  Saved new best model → resnet50_multilabel_cardd_best.pt\n",
      "\n",
      "Epoch 4/20\n",
      "  Train Loss: 0.0247 | Train Acc: 0.9908\n",
      "  Val Loss:   0.3703 | Val Acc:   0.9158\n",
      "  Val Micro F1: 0.8375\n",
      "    dent            F1: 0.8399\n",
      "    scratch         F1: 0.8627\n",
      "    crack           F1: 0.6667\n",
      "    glass shatter   F1: 0.9630\n",
      "    lamp broken     F1: 0.7566\n",
      "    tire flat       F1: 0.9483\n",
      "\n",
      "Epoch 5/20\n",
      "  Train Loss: 0.0149 | Train Acc: 0.9954\n",
      "  Val Loss:   0.3804 | Val Acc:   0.9183\n",
      "  Val Micro F1: 0.8409\n",
      "    dent            F1: 0.8448\n",
      "    scratch         F1: 0.8512\n",
      "    crack           F1: 0.6694\n",
      "    glass shatter   F1: 0.9627\n",
      "    lamp broken     F1: 0.7887\n",
      "    tire flat       F1: 0.9483\n",
      "  Saved new best model → resnet50_multilabel_cardd_best.pt\n",
      "\n",
      "Epoch 6/20\n",
      "  Train Loss: 0.1467 | Train Acc: 0.9409\n",
      "  Val Loss:   0.2471 | Val Acc:   0.9062\n",
      "  Val Micro F1: 0.8139\n",
      "    dent            F1: 0.7888\n",
      "    scratch         F1: 0.8273\n",
      "    crack           F1: 0.6878\n",
      "    glass shatter   F1: 0.9209\n",
      "    lamp broken     F1: 0.7862\n",
      "    tire flat       F1: 0.9091\n",
      "\n",
      "Epoch 7/20\n",
      "  Train Loss: 0.1344 | Train Acc: 0.9460\n",
      "  Val Loss:   0.2858 | Val Acc:   0.8957\n",
      "  Val Micro F1: 0.7890\n",
      "    dent            F1: 0.7942\n",
      "    scratch         F1: 0.8237\n",
      "    crack           F1: 0.4204\n",
      "    glass shatter   F1: 0.9559\n",
      "    lamp broken     F1: 0.6256\n",
      "    tire flat       F1: 0.8730\n",
      "\n",
      "Epoch 8/20\n",
      "  Train Loss: 0.1103 | Train Acc: 0.9567\n",
      "  Val Loss:   0.2499 | Val Acc:   0.9103\n",
      "  Val Micro F1: 0.8173\n",
      "    dent            F1: 0.8213\n",
      "    scratch         F1: 0.8240\n",
      "    crack           F1: 0.6170\n",
      "    glass shatter   F1: 0.9774\n",
      "    lamp broken     F1: 0.7477\n",
      "    tire flat       F1: 0.9074\n",
      "\n",
      "Epoch 9/20\n",
      "  Train Loss: 0.0874 | Train Acc: 0.9662\n",
      "  Val Loss:   0.2906 | Val Acc:   0.8936\n",
      "  Val Micro F1: 0.7911\n",
      "    dent            F1: 0.7877\n",
      "    scratch         F1: 0.7834\n",
      "    crack           F1: 0.6420\n",
      "    glass shatter   F1: 0.9774\n",
      "    lamp broken     F1: 0.7203\n",
      "    tire flat       F1: 0.9032\n",
      "\n",
      "Epoch 10/20\n",
      "  Train Loss: 0.0688 | Train Acc: 0.9732\n",
      "  Val Loss:   0.3154 | Val Acc:   0.9086\n",
      "  Val Micro F1: 0.8207\n",
      "    dent            F1: 0.8329\n",
      "    scratch         F1: 0.8238\n",
      "    crack           F1: 0.6429\n",
      "    glass shatter   F1: 0.9701\n",
      "    lamp broken     F1: 0.7653\n",
      "    tire flat       F1: 0.9174\n",
      "\n",
      "Epoch 11/20\n",
      "  Train Loss: 0.0668 | Train Acc: 0.9759\n",
      "  Val Loss:   0.3563 | Val Acc:   0.9056\n",
      "  Val Micro F1: 0.8208\n",
      "    dent            F1: 0.8136\n",
      "    scratch         F1: 0.8418\n",
      "    crack           F1: 0.6667\n",
      "    glass shatter   F1: 0.9699\n",
      "    lamp broken     F1: 0.7607\n",
      "    tire flat       F1: 0.8200\n",
      "\n",
      "Epoch 12/20\n",
      "  Train Loss: 0.0479 | Train Acc: 0.9814\n",
      "  Val Loss:   0.3068 | Val Acc:   0.9076\n",
      "  Val Micro F1: 0.8161\n",
      "    dent            F1: 0.8178\n",
      "    scratch         F1: 0.8248\n",
      "    crack           F1: 0.5970\n",
      "    glass shatter   F1: 0.9665\n",
      "    lamp broken     F1: 0.7641\n",
      "    tire flat       F1: 0.9032\n",
      "\n",
      "Epoch 13/20\n",
      "  Train Loss: 0.0352 | Train Acc: 0.9871\n",
      "  Val Loss:   0.3461 | Val Acc:   0.9138\n",
      "  Val Micro F1: 0.8236\n",
      "    dent            F1: 0.8053\n",
      "    scratch         F1: 0.8591\n",
      "    crack           F1: 0.5864\n",
      "    glass shatter   F1: 0.9738\n",
      "    lamp broken     F1: 0.7236\n",
      "    tire flat       F1: 0.9204\n",
      "\n",
      "Epoch 14/20\n",
      "  Train Loss: 0.0293 | Train Acc: 0.9902\n",
      "  Val Loss:   0.3771 | Val Acc:   0.9072\n",
      "  Val Micro F1: 0.8210\n",
      "    dent            F1: 0.8142\n",
      "    scratch         F1: 0.8421\n",
      "    crack           F1: 0.6476\n",
      "    glass shatter   F1: 0.9489\n",
      "    lamp broken     F1: 0.7507\n",
      "    tire flat       F1: 0.9106\n",
      "\n",
      "Epoch 15/20\n",
      "  Train Loss: 0.0210 | Train Acc: 0.9927\n",
      "  Val Loss:   0.3892 | Val Acc:   0.9093\n",
      "  Val Micro F1: 0.8291\n",
      "    dent            F1: 0.8270\n",
      "    scratch         F1: 0.8510\n",
      "    crack           F1: 0.6508\n",
      "    glass shatter   F1: 0.9630\n",
      "    lamp broken     F1: 0.7698\n",
      "    tire flat       F1: 0.9474\n",
      "\n",
      "Epoch 16/20\n",
      "  Train Loss: 0.0146 | Train Acc: 0.9953\n",
      "  Val Loss:   0.4149 | Val Acc:   0.9169\n",
      "  Val Micro F1: 0.8368\n",
      "    dent            F1: 0.8315\n",
      "    scratch         F1: 0.8545\n",
      "    crack           F1: 0.6949\n",
      "    glass shatter   F1: 0.9774\n",
      "    lamp broken     F1: 0.7633\n",
      "    tire flat       F1: 0.8819\n",
      "\n",
      "Epoch 17/20\n",
      "  Train Loss: 0.0072 | Train Acc: 0.9974\n",
      "  Val Loss:   0.4485 | Val Acc:   0.9191\n",
      "  Val Micro F1: 0.8399\n",
      "    dent            F1: 0.8385\n",
      "    scratch         F1: 0.8524\n",
      "    crack           F1: 0.6726\n",
      "    glass shatter   F1: 0.9738\n",
      "    lamp broken     F1: 0.7733\n",
      "    tire flat       F1: 0.9483\n",
      "\n",
      "Epoch 18/20\n",
      "  Train Loss: 0.0053 | Train Acc: 0.9983\n",
      "  Val Loss:   0.4838 | Val Acc:   0.9193\n",
      "  Val Micro F1: 0.8403\n",
      "    dent            F1: 0.8372\n",
      "    scratch         F1: 0.8538\n",
      "    crack           F1: 0.6796\n",
      "    glass shatter   F1: 0.9524\n",
      "    lamp broken     F1: 0.7855\n",
      "    tire flat       F1: 0.9180\n",
      "\n",
      "Epoch 19/20\n",
      "  Train Loss: 0.0036 | Train Acc: 0.9986\n",
      "  Val Loss:   0.5196 | Val Acc:   0.9113\n",
      "  Val Micro F1: 0.8314\n",
      "    dent            F1: 0.8223\n",
      "    scratch         F1: 0.8536\n",
      "    crack           F1: 0.6667\n",
      "    glass shatter   F1: 0.9774\n",
      "    lamp broken     F1: 0.7603\n",
      "    tire flat       F1: 0.9333\n",
      "\n",
      "Epoch 20/20\n",
      "  Train Loss: 0.0024 | Train Acc: 0.9996\n",
      "  Val Loss:   0.5458 | Val Acc:   0.9187\n",
      "  Val Micro F1: 0.8382\n",
      "    dent            F1: 0.8210\n",
      "    scratch         F1: 0.8496\n",
      "    crack           F1: 0.6953\n",
      "    glass shatter   F1: 0.9701\n",
      "    lamp broken     F1: 0.7863\n",
      "    tire flat       F1: 0.9412\n",
      "\n",
      "Training complete. Best val micro F1: 0.8408817648887634\n"
     ]
    }
   ],
   "source": [
    "best_val_f1 = 0.0\n",
    "checkpoint_path = \"resnet50_multilabel_cardd_best.pt\"\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # train\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_acc += multilabel_accuracy(logits, targets) * images.size(0)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_acc /= len(train_dataset)\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    metrics = {\n",
    "        \"tp\": torch.zeros(num_classes),\n",
    "        \"fp\": torch.zeros(num_classes),\n",
    "        \"fn\": torch.zeros(num_classes),\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, targets)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_acc += multilabel_accuracy(logits, targets) * images.size(0)\n",
    "\n",
    "            update_metrics(logits, targets, metrics)\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc /= len(val_dataset)\n",
    "    stats = compute_f1(metrics)\n",
    "    class_f1 = stats[\"f1\"]\n",
    "    micro_f1 = stats[\"micro_f1\"]\n",
    "\n",
    "    # report\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "    print(f\"  Val Micro F1: {micro_f1:.4f}\")\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        print(f\"    {name:15s} F1: {class_f1[i]:.4f}\") \n",
    "\n",
    "    #checkpoint\n",
    "    if micro_f1 > best_val_f1:\n",
    "        best_val_f1 = micro_f1\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"  Saved new best model → {checkpoint_path}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\nTraining complete. Best val micro F1:\", best_val_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0e59e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "bn1.running_mean\n",
      "bn1.running_var\n",
      "bn1.num_batches_tracked\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn1.running_mean\n",
      "layer1.0.bn1.running_var\n",
      "layer1.0.bn1.num_batches_tracked\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.bn2.running_mean\n",
      "layer1.0.bn2.running_var\n",
      "layer1.0.bn2.num_batches_tracked\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.bn3.running_mean\n",
      "layer1.0.bn3.running_var\n",
      "layer1.0.bn3.num_batches_tracked\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.0.downsample.1.running_mean\n",
      "layer1.0.downsample.1.running_var\n",
      "layer1.0.downsample.1.num_batches_tracked\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn1.running_mean\n",
      "layer1.1.bn1.running_var\n",
      "layer1.1.bn1.num_batches_tracked\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.bn2.running_mean\n",
      "layer1.1.bn2.running_var\n",
      "layer1.1.bn2.num_batches_tracked\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.1.bn3.running_mean\n",
      "layer1.1.bn3.running_var\n",
      "layer1.1.bn3.num_batches_tracked\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.bn1.running_mean\n",
      "layer1.2.bn1.running_var\n",
      "layer1.2.bn1.num_batches_tracked\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.bn2.running_mean\n",
      "layer1.2.bn2.running_var\n",
      "layer1.2.bn2.num_batches_tracked\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer1.2.bn3.running_mean\n",
      "layer1.2.bn3.running_var\n",
      "layer1.2.bn3.num_batches_tracked\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn1.running_mean\n",
      "layer2.0.bn1.running_var\n",
      "layer2.0.bn1.num_batches_tracked\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.bn2.running_mean\n",
      "layer2.0.bn2.running_var\n",
      "layer2.0.bn2.num_batches_tracked\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.bn3.running_mean\n",
      "layer2.0.bn3.running_var\n",
      "layer2.0.bn3.num_batches_tracked\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.0.downsample.1.running_mean\n",
      "layer2.0.downsample.1.running_var\n",
      "layer2.0.downsample.1.num_batches_tracked\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn1.running_mean\n",
      "layer2.1.bn1.running_var\n",
      "layer2.1.bn1.num_batches_tracked\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.bn2.running_mean\n",
      "layer2.1.bn2.running_var\n",
      "layer2.1.bn2.num_batches_tracked\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.1.bn3.running_mean\n",
      "layer2.1.bn3.running_var\n",
      "layer2.1.bn3.num_batches_tracked\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.bn1.running_mean\n",
      "layer2.2.bn1.running_var\n",
      "layer2.2.bn1.num_batches_tracked\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.bn2.running_mean\n",
      "layer2.2.bn2.running_var\n",
      "layer2.2.bn2.num_batches_tracked\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.2.bn3.running_mean\n",
      "layer2.2.bn3.running_var\n",
      "layer2.2.bn3.num_batches_tracked\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.bn1.running_mean\n",
      "layer2.3.bn1.running_var\n",
      "layer2.3.bn1.num_batches_tracked\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.bn2.running_mean\n",
      "layer2.3.bn2.running_var\n",
      "layer2.3.bn2.num_batches_tracked\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer2.3.bn3.running_mean\n",
      "layer2.3.bn3.running_var\n",
      "layer2.3.bn3.num_batches_tracked\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn1.running_mean\n",
      "layer3.0.bn1.running_var\n",
      "layer3.0.bn1.num_batches_tracked\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.bn2.running_mean\n",
      "layer3.0.bn2.running_var\n",
      "layer3.0.bn2.num_batches_tracked\n",
      "layer3.0.conv3.weight\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.0.bn3.running_mean\n",
      "layer3.0.bn3.running_var\n",
      "layer3.0.bn3.num_batches_tracked\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.0.downsample.1.running_mean\n",
      "layer3.0.downsample.1.running_var\n",
      "layer3.0.downsample.1.num_batches_tracked\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn1.running_mean\n",
      "layer3.1.bn1.running_var\n",
      "layer3.1.bn1.num_batches_tracked\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.bn2.running_mean\n",
      "layer3.1.bn2.running_var\n",
      "layer3.1.bn2.num_batches_tracked\n",
      "layer3.1.conv3.weight\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.1.bn3.running_mean\n",
      "layer3.1.bn3.running_var\n",
      "layer3.1.bn3.num_batches_tracked\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.bn1.running_mean\n",
      "layer3.2.bn1.running_var\n",
      "layer3.2.bn1.num_batches_tracked\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.bn2.running_mean\n",
      "layer3.2.bn2.running_var\n",
      "layer3.2.bn2.num_batches_tracked\n",
      "layer3.2.conv3.weight\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.2.bn3.running_mean\n",
      "layer3.2.bn3.running_var\n",
      "layer3.2.bn3.num_batches_tracked\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.bn1.running_mean\n",
      "layer3.3.bn1.running_var\n",
      "layer3.3.bn1.num_batches_tracked\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.bn2.running_mean\n",
      "layer3.3.bn2.running_var\n",
      "layer3.3.bn2.num_batches_tracked\n",
      "layer3.3.conv3.weight\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.3.bn3.running_mean\n",
      "layer3.3.bn3.running_var\n",
      "layer3.3.bn3.num_batches_tracked\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.bn1.running_mean\n",
      "layer3.4.bn1.running_var\n",
      "layer3.4.bn1.num_batches_tracked\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.bn2.running_mean\n",
      "layer3.4.bn2.running_var\n",
      "layer3.4.bn2.num_batches_tracked\n",
      "layer3.4.conv3.weight\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.4.bn3.running_mean\n",
      "layer3.4.bn3.running_var\n",
      "layer3.4.bn3.num_batches_tracked\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.bn1.running_mean\n",
      "layer3.5.bn1.running_var\n",
      "layer3.5.bn1.num_batches_tracked\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.bn2.running_mean\n",
      "layer3.5.bn2.running_var\n",
      "layer3.5.bn2.num_batches_tracked\n",
      "layer3.5.conv3.weight\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer3.5.bn3.running_mean\n",
      "layer3.5.bn3.running_var\n",
      "layer3.5.bn3.num_batches_tracked\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn1.running_mean\n",
      "layer4.0.bn1.running_var\n",
      "layer4.0.bn1.num_batches_tracked\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.bn2.running_mean\n",
      "layer4.0.bn2.running_var\n",
      "layer4.0.bn2.num_batches_tracked\n",
      "layer4.0.conv3.weight\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.bn3.running_mean\n",
      "layer4.0.bn3.running_var\n",
      "layer4.0.bn3.num_batches_tracked\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.0.downsample.1.running_mean\n",
      "layer4.0.downsample.1.running_var\n",
      "layer4.0.downsample.1.num_batches_tracked\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn1.running_mean\n",
      "layer4.1.bn1.running_var\n",
      "layer4.1.bn1.num_batches_tracked\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.bn2.running_mean\n",
      "layer4.1.bn2.running_var\n",
      "layer4.1.bn2.num_batches_tracked\n",
      "layer4.1.conv3.weight\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.1.bn3.running_mean\n",
      "layer4.1.bn3.running_var\n",
      "layer4.1.bn3.num_batches_tracked\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.bn1.running_mean\n",
      "layer4.2.bn1.running_var\n",
      "layer4.2.bn1.num_batches_tracked\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.bn2.running_mean\n",
      "layer4.2.bn2.running_var\n",
      "layer4.2.bn2.num_batches_tracked\n",
      "layer4.2.conv3.weight\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "layer4.2.bn3.running_mean\n",
      "layer4.2.bn3.running_var\n",
      "layer4.2.bn3.num_batches_tracked\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.3.weight\n",
      "fc.3.bias\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(\"resnet50_multilabel_cardd_best.pt\", map_location=\"cpu\")\n",
    "\n",
    "for k in state.keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778fe45f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab8f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "def load_trained_resnet(num_classes=6):\n",
    "    model = models.resnet50(weights=None)   # DO NOT wrap in a class\n",
    "\n",
    "    # exact classifier you used during training\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_trained_resnet(num_classes=6)\n",
    "\n",
    "state = torch.load(\"resnet50_multilabel_cardd_best.pt\", map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(state) \n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [00:30<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss: 0.3428\n",
      "Micro-F1:  0.8411\n",
      "\n",
      "Per-class F1:\n",
      "  Class 0: 0.8443\n",
      "  Class 1: 0.8944\n",
      "  Class 2: 0.5800\n",
      "  Class 3: 0.9333\n",
      "  Class 4: 0.7634\n",
      "  Class 5: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# recreate trained model w/ loaded weights\n",
    "\n",
    "def load_trained_resnet(num_classes=6):\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = load_trained_resnet(num_classes=6).to(device)\n",
    "\n",
    "state = torch.load(\"resnet50_multilabel_cardd_best.pt\", map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "\n",
    "# compute metrics\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def update_metrics(logits, targets, metrics, threshold=0.5):\n",
    "    preds = (torch.sigmoid(logits) >= threshold).float()\n",
    "\n",
    "    metrics[\"tp\"] += ((preds == 1) & (targets == 1)).sum(dim=0).cpu()\n",
    "    metrics[\"fp\"] += ((preds == 1) & (targets == 0)).sum(dim=0).cpu()\n",
    "    metrics[\"fn\"] += ((preds == 0) & (targets == 1)).sum(dim=0).cpu()\n",
    "\n",
    "def compute_f1(metrics):\n",
    "    tp, fp, fn = metrics[\"tp\"], metrics[\"fp\"], metrics[\"fn\"]\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn + 1e-7)\n",
    "    micro_f1 = (2 * tp.sum()) / (2 * tp.sum() + fp.sum() + fn.sum() + 1e-7)\n",
    "    return f1, micro_f1\n",
    "\n",
    "\n",
    "# run on test set\n",
    "\n",
    "test_loss = 0\n",
    "metrics = {\"tp\": torch.zeros(6), \"fp\": torch.zeros(6), \"fn\": torch.zeros(6)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "\n",
    "        update_metrics(logits, labels, metrics)\n",
    "\n",
    "test_loss /= len(test_dataset)\n",
    "f1_per_class, micro_f1 = compute_f1(metrics)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Micro-F1:  {micro_f1:.4f}\")\n",
    "print(\"\\nPer-class F1:\")\n",
    "for i, f1 in enumerate(f1_per_class):\n",
    "    print(f\"  Class {i}: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8ca39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/prisriva/miniconda3/envs/cardd/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/prisriva/miniconda3/envs/cardd/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/prisriva/miniconda3/envs/cardd/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/prisriva/miniconda3/envs/cardd/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.3.3-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, joblib, scikit-learn, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [pandas]2m5/6\u001b[0m [pandas]learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 pandas-2.3.3 pytz-2025.2 scikit-learn-1.7.2 threadpoolctl-3.6.0 tzdata-2025.2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# compute classification report and per-class confusion matrices for multilabel test set\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m y_trues \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# compute classification report and per-class confusion matrices for multilabel test set\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "        y_preds.append(preds)\n",
    "        y_trues.append(labels.cpu().numpy().astype(int))\n",
    "\n",
    "y_true = np.vstack(y_trues)   # shape: (N, num_classes)\n",
    "y_pred = np.vstack(y_preds)\n",
    "\n",
    "# classification report (per-class)\n",
    "print(\"Classification report (per-class):\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "# confusion matrices per class and summary table (TP, FP, FN, TN)\n",
    "rows = []\n",
    "for i, name in enumerate(class_names):\n",
    "    cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "    # pad to 2x2 if necessary\n",
    "    cm2 = np.zeros((2, 2), dtype=int)\n",
    "    cm2[: cm.shape[0], : cm.shape[1]] = cm\n",
    "    tn, fp, fn, tp = cm2.ravel()\n",
    "    rows.append({\"class\": name, \"TP\": int(tp), \"FP\": int(fp), \"FN\": int(fn), \"TN\": int(tn)})\n",
    "    print(f\"\\nConfusion matrix for '{name}':\\n{cm2}\")\n",
    "\n",
    "summary_df = pd.DataFrame(rows).set_index(\"class\")\n",
    "print(\"\\nPer-class confusion summary:\\n\")\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cardd)",
   "language": "python",
   "name": "cardd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
