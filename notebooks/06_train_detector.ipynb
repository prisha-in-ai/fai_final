{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cbafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Classes: {1: 'dent', 2: 'scratch', 3: 'crack', 4: 'glass shatter', 5: 'lamp broken', 6: 'tire flat'}\n"
     ]
    }
   ],
   "source": [
    "#Imports, paths to (augmented) detector dataset, seeds, hyperparameters.\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"mps\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Paths (aligned with augmentation notebook)\n",
    "BASE_DATA_ROOT = Path(\"/Users/stephenmacris/Documents/School/CS5100/Project/CarDD_release/CarDD_COCO\")\n",
    "\n",
    "DETECTOR_ROOT = BASE_DATA_ROOT / \"detector\"\n",
    "AUG_ROOT = BASE_DATA_ROOT / \"augmented\" / \"detector\"\n",
    "\n",
    "TRAIN_IMG_DIR = DETECTOR_ROOT / \"train\" / \"images\"\n",
    "TRAIN_ANN = DETECTOR_ROOT / \"train\" / \"annotations\" / \"annotations.json\"\n",
    "\n",
    "VAL_IMG_DIR = DETECTOR_ROOT / \"val\" / \"images\"\n",
    "VAL_ANN = DETECTOR_ROOT / \"val\" / \"annotations\" / \"annotations.json\"\n",
    "\n",
    "TEST_IMG_DIR = DETECTOR_ROOT / \"test\" / \"images\"\n",
    "TEST_ANN = DETECTOR_ROOT / \"test\" / \"annotations\" / \"annotations.json\"\n",
    "\n",
    "with open(TRAIN_ANN, \"r\") as f:\n",
    "    train_coco = json.load(f)\n",
    "\n",
    "categories = train_coco.get(\"categories\", [])\n",
    "category_id_to_name = {c[\"id\"]: c[\"name\"] for c in categories}\n",
    "NUM_CLASSES = len(categories) + 1  # +1 for background\n",
    "print(\"Classes:\", category_id_to_name)\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "CHECKPOINT_PATH = \"fasterrcnn_cardd_best.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3496e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 704, Val batches: 203\n"
     ]
    }
   ],
   "source": [
    "#Dataset/Dataloader: custom Dataset to read images + bboxes/labels from COCO, apply train/val transforms, \n",
    "#collate function for variable targets.\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, image, target):\n",
    "        return F.to_tensor(image), target\n",
    "\n",
    "class RandomHorizontalFlip:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.p:\n",
    "            width, _ = image.size\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            if \"boxes\" in target:\n",
    "                boxes = target[\"boxes\"].clone()\n",
    "                boxes[:, [0, 2]] = width - boxes[:, [2, 0]]\n",
    "                target[\"boxes\"] = boxes\n",
    "        return image, target\n",
    "\n",
    "def get_transform(train=True):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(RandomHorizontalFlip(0.5))\n",
    "    transforms.append(ToTensor())\n",
    "    return Compose(transforms)\n",
    "\n",
    "class CocoDetectionDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path, ann_path: Path, transforms=None):\n",
    "        with open(ann_path, \"r\") as f:\n",
    "            coco = json.load(f)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.transforms = transforms\n",
    "        self.id_to_image = {img[\"id\"]: img for img in coco.get(\"images\", [])}\n",
    "        self.anns_by_image = defaultdict(list)\n",
    "        for ann in coco.get(\"annotations\", []):\n",
    "            self.anns_by_image[ann[\"image_id\"]].append(ann)\n",
    "        self.image_ids = list(self.id_to_image.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_info = self.id_to_image[image_id]\n",
    "        img_path = self.images_dir / img_info[\"file_name\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        areas = []\n",
    "        iscrowd = []\n",
    "\n",
    "        for ann in self.anns_by_image.get(image_id, []):\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "            areas.append(ann.get(\"area\", w * h))\n",
    "            iscrowd.append(ann.get(\"iscrowd\", 0))\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        areas = torch.tensor(areas, dtype=torch.float32)\n",
    "        iscrowd = torch.tensor(iscrowd, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([image_id]),\n",
    "            \"area\": areas,\n",
    "            \"iscrowd\": iscrowd,\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            image, target = self.transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataset = CocoDetectionDataset(TRAIN_IMG_DIR, TRAIN_ANN, transforms=get_transform(train=True))\n",
    "val_dataset = CocoDetectionDataset(VAL_IMG_DIR, VAL_ANN, transforms=get_transform(train=False))\n",
    "\n",
    "test_dataset = None\n",
    "if TEST_ANN.exists():\n",
    "    test_dataset = CocoDetectionDataset(TEST_IMG_DIR, TEST_ANN, transforms=get_transform(train=False))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "test_loader = None\n",
    "if test_dataset:\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9379e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained MobileNetV3-320 FPN weights; replacing head for NUM_CLASSES\n",
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(320,), max_size=480, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-1): 2 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model definition: choose detector (e.g., torchvision fasterrcnn_resnet50_fpn or YOLOv5/YOLOv8 if available); \n",
    "#adapt num_classes to the damage categories.\n",
    "from torchvision.models.detection import (\n",
    "    fasterrcnn_mobilenet_v3_large_320_fpn,\n",
    "    FasterRCNN_MobileNet_V3_Large_320_FPN_Weights,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "try:\n",
    "    weights = FasterRCNN_MobileNet_V3_Large_320_FPN_Weights.DEFAULT\n",
    "    print(\"Using pretrained MobileNetV3-320 FPN weights; replacing head for NUM_CLASSES\")\n",
    "except Exception:\n",
    "    weights = None\n",
    "    print(\"Pretrained weights unavailable; initializing backbone randomly and replacing head\")\n",
    "\n",
    "model = fasterrcnn_mobilenet_v3_large_320_fpn(\n",
    "    weights=weights,\n",
    "    min_size=320,   # shorter side\n",
    "    max_size=480,   # cap the longer side\n",
    ")\n",
    "\n",
    "# replace the head for your classes\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "\n",
    "model.to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418c1dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1:   0%|          | 1/704 [00:44<8:35:40, 44.01s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 0/704 | loss 3.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1:   0%|          | 3/704 [06:29<23:28:15, 120.54s/batch]"
     ]
    }
   ],
   "source": [
    "#Training loop: optimizer/scheduler setup, epoch loop with loss logging, checkpointing best model by val mAP.\n",
    "from torchvision.ops import box_iou\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_map(model, data_loader, device, iou_thresholds=None, score_thresh=0.05):\n",
    "    if iou_thresholds is None:\n",
    "        iou_thresholds = [0.5] + [round(x, 2) for x in np.arange(0.55, 0.96, 0.05)]\n",
    "\n",
    "    stats_per_cls = {t: defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0}) for t in iou_thresholds}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "\n",
    "            for output, target in zip(outputs, targets):\n",
    "                gt_boxes = target[\"boxes\"].to(device)\n",
    "                gt_labels = target[\"labels\"].to(device)\n",
    "\n",
    "                pred_boxes = output[\"boxes\"].to(device)\n",
    "                pred_labels = output[\"labels\"].to(device)\n",
    "                scores = output[\"scores\"].to(device)\n",
    "\n",
    "                keep = scores >= score_thresh\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_labels = pred_labels[keep]\n",
    "\n",
    "                for t in iou_thresholds:\n",
    "                    matched = set()\n",
    "                    for pb, pl in zip(pred_boxes, pred_labels):\n",
    "                        cls = int(pl.item())\n",
    "                        mask = (gt_labels == pl)\n",
    "                        if mask.sum() == 0:\n",
    "                            stats_per_cls[t][cls][\"fp\"] += 1\n",
    "                            continue\n",
    "\n",
    "                        ious = box_iou(pb.unsqueeze(0), gt_boxes[mask]).squeeze(0)\n",
    "                        if ious.numel() == 0:\n",
    "                            stats_per_cls[t][cls][\"fp\"] += 1\n",
    "                            continue\n",
    "                        max_iou, max_idx = ious.max(0)\n",
    "                        if max_iou >= t:\n",
    "                            global_idx = mask.nonzero(as_tuple=False).squeeze(1)[max_idx].item()\n",
    "                            if global_idx not in matched:\n",
    "                                matched.add(global_idx)\n",
    "                                stats_per_cls[t][cls][\"tp\"] += 1\n",
    "                            else:\n",
    "                                stats_per_cls[t][cls][\"fp\"] += 1\n",
    "                        else:\n",
    "                            stats_per_cls[t][cls][\"fp\"] += 1\n",
    "\n",
    "                    # FN: ground truths of each class that were not matched\n",
    "                    for cls in gt_labels.unique():\n",
    "                        cls_id = int(cls.item())\n",
    "                        cls_mask = (gt_labels == cls)\n",
    "                        gt_indices = cls_mask.nonzero(as_tuple=False).squeeze(1).tolist()\n",
    "                        matched_cls = [idx for idx in matched if int(gt_labels[idx].item()) == cls_id]\n",
    "                        fn = len(gt_indices) - len(matched_cls)\n",
    "                        stats_per_cls[t][cls_id][\"fn\"] += max(fn, 0)\n",
    "\n",
    "    map_per_t = []\n",
    "    map50 = 0.0\n",
    "    per_class_map50 = {}\n",
    "\n",
    "    for idx, t in enumerate(iou_thresholds):\n",
    "        cls_scores = []\n",
    "        for cls_id, vals in stats_per_cls[t].items():\n",
    "            tp, fp, fn = vals[\"tp\"], vals[\"fp\"], vals[\"fn\"]\n",
    "            denom = tp + fp + fn + 1e-6\n",
    "            cls_score = tp / denom\n",
    "            cls_scores.append(cls_score)\n",
    "            if t == 0.5:\n",
    "                per_class_map50[cls_id] = cls_score\n",
    "        if cls_scores:\n",
    "            score_t = float(np.mean(cls_scores))\n",
    "            map_per_t.append(score_t)\n",
    "            if t == 0.5:\n",
    "                map50 = score_t\n",
    "        else:\n",
    "            map_per_t.append(0.0)\n",
    "            if t == 0.5:\n",
    "                map50 = 0.0\n",
    "\n",
    "    map5095 = float(np.mean(map_per_t)) if map_per_t else 0.0\n",
    "    return map50, map5095, per_class_map50\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "best_map50 = 0.0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i, (images, targets) in enumerate(tqdm(train_loader, desc=f\"train epoch {epoch+1}\", unit=\"batch\")):\n",
    "        images = [img.to(DEVICE) for img in images]\n",
    "        targets = [\n",
    "            {k: v.to(DEVICE) if torch.is_tensor(v) else v for k, v in t.items()}\n",
    "            for t in targets\n",
    "        ]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"  batch {i}/{len(train_loader)} | loss {losses.item():.4f}\")\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    avg_loss = epoch_loss / max(len(train_loader), 1)\n",
    "\n",
    "    val_map50, val_map5095, _ = evaluate_map(model, val_loader, DEVICE)\n",
    "\n",
    "    if val_map50 > best_map50:\n",
    "        best_map50 = val_map50\n",
    "        torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        print(f\"Epoch {epoch+1}: new best mAP@0.5={val_map50:.4f} â†’ saved {CHECKPOINT_PATH}\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} | loss={avg_loss:.4f} | val mAP@0.5={val_map50:.4f} | val mAP@[0.5:0.95]={val_map5095:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eaef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation: compute mAP@0.5 and mAP@[0.5:0.95] on val/test; print per-class AP.\n",
    "# Load best checkpoint if available\n",
    "if Path(CHECKPOINT_PATH).exists():\n",
    "    state = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    print(f\"Loaded checkpoint: {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(\"No checkpoint found; evaluating current model state.\")\n",
    "\n",
    "val_map50, val_map5095, val_per_class = evaluate_map(model, val_loader, DEVICE)\n",
    "print(f\"Validation mAP@0.5: {val_map50:.4f} | mAP@[0.5:0.95]: {val_map5095:.4f}\")\n",
    "for cls_id, score in sorted(val_per_class.items()):\n",
    "    name = category_id_to_name.get(cls_id, str(cls_id))\n",
    "    print(f\"  {name}: {score:.4f}\")\n",
    "\n",
    "if test_loader is not None:\n",
    "    test_map50, test_map5095, test_per_class = evaluate_map(model, test_loader, DEVICE)\n",
    "    print(f\"\\nTest mAP@0.5: {test_map50:.4f} | mAP@[0.5:0.95]: {test_map5095:.4f}\")\n",
    "    for cls_id, score in sorted(test_per_class.items()):\n",
    "        name = category_id_to_name.get(cls_id, str(cls_id))\n",
    "        print(f\"  {name}: {score:.4f}\")\n",
    "else:\n",
    "    print(\"Test set not found; skipping test evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e041f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference demo: run trained detector on a few test images, visualize and save predicted boxes/scores for qualitative review\n",
    "from PIL import ImageDraw\n",
    "\n",
    "sample_images = list(TEST_IMG_DIR.glob(\"*.jpg\"))[:3] if TEST_IMG_DIR.exists() else []\n",
    "if not sample_images:\n",
    "    sample_images = list(VAL_IMG_DIR.glob(\"*.jpg\"))[:3]\n",
    "\n",
    "score_threshold = 0.5\n",
    "model.eval()\n",
    "\n",
    "for img_path in sample_images:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = F.to_tensor(img).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model([img_tensor])[0]\n",
    "\n",
    "    keep = output[\"scores\"] >= score_threshold\n",
    "    boxes = output[\"boxes\"][keep].cpu()\n",
    "    labels = output[\"labels\"][keep].cpu()\n",
    "    scores = output[\"scores\"][keep].cpu()\n",
    "\n",
    "    vis = img.copy()\n",
    "    draw = ImageDraw.Draw(vis)\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        cls_name = category_id_to_name.get(int(label.item()), str(int(label.item())))\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "        draw.text((x1 + 2, y1 + 2), f\"{cls_name}: {score:.2f}\", fill=\"yellow\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(img_path.name)\n",
    "    plt.imshow(vis)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
